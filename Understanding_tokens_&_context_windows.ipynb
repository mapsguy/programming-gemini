{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapsguy/programming-gemini/blob/main/Understanding_tokens_%26_context_windows.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u26puzb3HyT9"
      },
      "outputs": [],
      "source": [
        "#step 1: install/upgrade the latest genai SDK\n",
        "%pip install google-genai --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the genai library\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "_jqkjaSLSGUB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "0bQfgHbwesFe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 2: Configure with your API key\n",
        "client = genai.configure(api_key=userdata.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "#If you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "NRmQ0FpeSSnL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 3: test your access by listing the models\n",
        "print(\"All Base Model Details:\")\n",
        "# Iterate through each model and print the full object\n",
        "for model in client.models.list(config={'query_base': True}): #\n",
        "    print(model)\n",
        "    # You can also access specific attributes, e.g.:\n",
        "    print(f\"Name: {model.name}\") #\n",
        "    print(f\"Display Name: {model.display_name}\") #\n",
        "    print(f\"Supported Actions: {model.supported_actions}\") #\n",
        "    print(f\"Endpoints: {model.endpoints}\") #\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nAll Tuned Model Details:\")\n",
        "for model in client.models.list(config={'query_base': False}): #\n",
        "    print(model)\n",
        "    print(f\"Name: {model.name}\") #\n",
        "    print(f\"Tuned Model Info: {model.tuned_model_info}\") #\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "tjguGPO0WDDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4: Get model details\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "try:\n",
        "    model_details = client.models.get(model=model_name) #\n",
        "    print(f\"Details for model '{model_name}':\")\n",
        "    print(f\"Model Name: {model_details.name}\")\n",
        "    print(f\"Input Token Limit: {model_details.input_token_limit}\")\n",
        "    print(f\"Output Token Limit: {model_details.output_token_limit}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving model details for '{model_name}': {e}\")"
      ],
      "metadata": {
        "id": "fVomhgC-t5j1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831439f6-b851-4ec3-ce31-75a89f1da323"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Details for model 'models/gemini-2.5-flash-preview-05-20':\n",
            "Model Name: models/gemini-2.5-flash-preview-05-20\n",
            "Input Token Limit: 1048576\n",
            "Output Token Limit: 65536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 5: Determining the token count for the intended prompt\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash-preview-05-20\")\n",
        "\n",
        "#count tokens for text\n",
        "response = model.count_tokens(\"Why is the sky blue?\")\n",
        "print(f\"Token count: {response.total_tokens}\")"
      ],
      "metadata": {
        "id": "oppq_uJCvhux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "23fdbce7-842c-48ef-87af-8135e462f5ea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token count: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 6: count tokens for multimodal input (text and image)\n",
        "# Note: Requires image data loaded appropriately\n",
        "from PIL import Image\n",
        "\n",
        "cat = Image.open(\"/content/cat.jpeg\")\n",
        "response = model.generate_content([\"Explain this image:\", cat])\n",
        "response1 = model.count_tokens([\"Explain this image:\", cat])\n",
        "print(response.text)\n",
        "print(f\"Token count: {response1.total_tokens}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "2gYx4gOWfSCA",
        "outputId": "3fadfc6e-4a4f-4eca-96ab-b82206d381d4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image is a **close-up portrait of a domestic cat**, specifically a **brown tabby** cat.\n",
            "\n",
            "Here's a breakdown of what's visible:\n",
            "\n",
            "*   **Subject:** The central and sole subject is the cat's face, filling most of the frame.\n",
            "*   **Fur:** The cat has a classic tabby pattern with dark brown/black stripes and swirls over a lighter brown or greyish-brown base coat. There are notable darker markings on its forehead forming an 'M' shape, typical of tabby cats.\n",
            "*   **Eyes:** Its most striking feature are its large, intensely **golden-yellow or amber eyes**, which are wide open and staring directly at the viewer. The eyes have a very slight downward tilt at the inner corners, contributing to the cat's expression.\n",
            "*   **Expression:** The cat has a very distinct and widely recognized expression often interpreted by humans as **\"grumpy,\" \"annoyed,\" \"stern,\" or \"unimpressed.\"** This is primarily conveyed by the way its brow is furrowed, giving it a somewhat scowling look, and the straight, slightly downturned line of its mouth.\n",
            "*   **Whiskers:** Long, prominent white whiskers fan out from both sides of its muzzle.\n",
            "*   **Ears:** Its ears are upright and pointed, covered in the same tabby fur.\n",
            "*   **Lighting and Focus:** The lighting is soft and even, highlighting the cat's features. The cat's face, especially its eyes, is in sharp focus, while the background is softly blurred (a bokeh effect), making the cat stand out.\n",
            "*   **Background:** The background is an indistinct, light grey or off-white color. At the very bottom of the frame, a small portion of what appears to be a soft, textured blue or grey fabric (possibly a blanket or cushion) is visible, suggesting the cat is resting.\n",
            "\n",
            "Overall, the image is a high-quality photograph that perfectly captures a cat with a very expressive, almost human-like \"grumpy\" demeanor, which makes it quite compelling and often humorous.\n",
            "Token count: 262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5YTLg6gHiSGr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}