{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapsguy/programming-gemini/blob/main/generating_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the genai library\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "_jqkjaSLSGUB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 2: AIStudio: read the api key from the user data\n",
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "#If you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "NRmQ0FpeSSnL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"models/gemini-2.0-flash-live-001\""
      ],
      "metadata": {
        "id": "mq1WXsB0VI9R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic workflow: text to audio with Live API\n",
        "\n",
        "import asyncio\n",
        "import wave\n",
        "\n",
        "config = {\"response_modalities\": [\"AUDIO\"]}\n",
        "\n",
        "async def main():\n",
        "  text_prompt=\"What is your favorite color?\"\n",
        "  print(f\"Attempting to generate audio for: {text_prompt}\")\n",
        "  async with client.aio.live.connect(model=model_name, config=config) as session:\n",
        "    wf = wave.open(\"audio.wav\", \"wb\")\n",
        "    wf.setnchannels(1)\n",
        "    wf.setsampwidth(2)\n",
        "    wf.setframerate(24000)\n",
        "\n",
        "    await session.send_client_content(\n",
        "        turns={\"role\": \"user\", \"parts\": [{\"text\": text_prompt}]}, turn_complete=True)\n",
        "\n",
        "    async for response in session.receive():\n",
        "      if response.data is not None:\n",
        "        wf.writeframes(response.data)\n",
        "      #Transcription?\n",
        "      #if response.server_content.input_transcription:\n",
        "        #print('Transcript:', response.server_content.input_transcription.text)\n",
        "\n",
        "\n",
        "    wf.close()\n",
        "    print(\"Audio generation complete\")\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKMd6qrum3OM",
        "outputId": "409a39f5-f2f5-4874-b442-69fbeb9c361b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to generate audio for: What is your favorite color?\n",
            "Audio generation complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transcribe the generated audio\n",
        "audio_file = client.files.upload(file=\"/content/audio.wav\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"models/gemini-2.5-flash-preview-05-20\",\n",
        "     contents=[\"Please transcribe this audio.\", audio_file])\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbDl96PXmhFU",
        "outputId": "c5ea2ada-eaed-4740-c408-9c9986b1a511"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As a language model, I don't have personal preferences like favorite colors. Is there anything else I can help you with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating audio after configuring the speech output (specifying a voice/language)\n",
        "from google.genai import types\n",
        "\n",
        "gen_config = {\n",
        "    \"response_modalities\": [\"AUDIO\"],\n",
        "    \"speech_config\": {\n",
        "        \"voice_config\":{\"prebuilt_voice_config\": {\"voice_name\": \"Kore\"}},\n",
        "        \"language_code\": \"en-US\"\n",
        "    }\n",
        "}\n",
        "\n",
        "async def main():\n",
        "  text_prompt=\"Tell us a short story.\"\n",
        "  print(f\"Attempting to generate audio for: {text_prompt}\")\n",
        "  async with client.aio.live.connect(model=model_name, config=gen_config) as session:\n",
        "    wf = wave.open(\"audio.wav\", \"wb\")\n",
        "    wf.setnchannels(1)\n",
        "    wf.setsampwidth(2)\n",
        "    wf.setframerate(24000)\n",
        "\n",
        "    await session.send_client_content(\n",
        "        turns={\"role\": \"user\", \"parts\": [{\"text\": text_prompt}]}, turn_complete=True)\n",
        "\n",
        "    async for response in session.receive():\n",
        "      if response.data is not None:\n",
        "        wf.writeframes(response.data)\n",
        "\n",
        "    wf.close()\n",
        "    print(\"Audio generation complete\")\n",
        "\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZXplBbgpsXi",
        "outputId": "b59a748a-21c5-48cf-e9df-fdd594021c77"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to generate audio for: Tell us a short story.\n",
            "Audio generation complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transcribe the short story generated above\n",
        "audio_file = client.files.upload(file=\"/content/audio.wav\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"models/gemini-2.5-flash-preview-05-20\",\n",
        "     contents=[\"Please transcribe this audio.\", audio_file])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYiLLyeKs_US",
        "outputId": "b4acbd11-c311-4be9-96de-e37fb3ed63fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's a short story for you. A firefly named Flicker was born without a light. The other fireflies teased him, but Flicker didn't give up. He tried everything to spark his light, but nothing worked. One day, feeling dejected, he sat alone in a field of flowers. A little girl, seeing his sadness, gently touched him. Suddenly, Flicker burst into a brilliant glow. The girl's kindness had ignited his inner light. From that day on, Flicker shone brighter than any other firefly, teaching everyone that kindness can spark the light within us all. Would you like to hear another story?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ax5gHmCItKNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}