{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapsguy/programming-gemini/blob/main/basic_prompting_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u26puzb3HyT9",
        "outputId": "b06c01f6-9055-4442-8869-6517afbb03c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/199.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m194.6/199.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#step 1: install/upgrade the latest genai SDK\n",
        "%pip install google-genai --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the genai library\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "_jqkjaSLSGUB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: AIStudio: read the api key from the user data\n",
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "#If you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "NRmQ0FpeSSnL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: Vertex AI: read the api key from the user data\n",
        "\n",
        "#for vertex, you need to have a service account or login/auth\n",
        "#login as the current user for colab testing purposes\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#then configure the client with the project and location settings\n",
        "\n",
        "#Uncomment the following if you are running on Vertex setup\n",
        "\n",
        "#using the colab userdata\n",
        "#from google.colab import userdata\n",
        "#client = genai.Client(vertexai=True, #ensure to turn on VertexAI\n",
        "#                      project=userdata.get(\"GOOGLE_CLOUD_PROJECT\"),\n",
        "#                      location=userdata.get(\"GOOGLE_CLOUD_REGION\")) # e.g., 'us-central1'\n",
        "\n",
        "#or use the folliwing if you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(vertexai=True,\n",
        "#                      project=os.environ[\"GOOGLE_CLOUD_PROJECT\"],\n",
        "#                      location=os.environ[\"GOOGLE_CLOUD_REGION\"]) # e.g., 'us-central1'"
      ],
      "metadata": {
        "id": "P60EQlueSQOZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "6aa069e8-b505-4445-fadd-66efb97885fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3e8b21c2b1eb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#login as the current user for colab testing purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#then configure the client with the project and location settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    261\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step3: test your access by listing the models\n",
        "print(\"All Base Model Details:\")\n",
        "# Iterate through each model and print the full object\n",
        "for model in client.models.list(config={'query_base': True}): #\n",
        "    print(model)\n",
        "    # You can also access specific attributes, e.g.:\n",
        "    print(f\"Name: {model.name}\") #\n",
        "    print(f\"Display Name: {model.display_name}\") #\n",
        "    print(f\"Supported Actions: {model.supported_actions}\") #\n",
        "    print(f\"Endpoints: {model.endpoints}\") #\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nAll Tuned Model Details:\")\n",
        "for model in client.models.list(config={'query_base': False}): #\n",
        "    print(model)\n",
        "    print(f\"Name: {model.name}\") #\n",
        "    print(f\"Tuned Model Info: {model.tuned_model_info}\") #\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "tjguGPO0WDDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae23df3-8df6-4e62-cc26-2565ad387b8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Base Model Details:\n",
            "name='models/embedding-gecko-001' display_name='Embedding Gecko' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1024 output_token_limit=1 supported_actions=['embedText', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/embedding-gecko-001\n",
            "Display Name: Embedding Gecko\n",
            "Supported Actions: ['embedText', 'countTextTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.0-pro-vision-latest' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.0-pro-vision-latest\n",
            "Display Name: Gemini 1.0 Pro Vision\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-pro-vision' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-pro-vision\n",
            "Display Name: Gemini 1.0 Pro Vision\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-pro-latest' display_name='Gemini 1.5 Pro Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-pro-latest\n",
            "Display Name: Gemini 1.5 Pro Latest\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-pro-001' display_name='Gemini 1.5 Pro 001' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-pro-001\n",
            "Display Name: Gemini 1.5 Pro 001\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-pro-002' display_name='Gemini 1.5 Pro 002' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-pro-002\n",
            "Display Name: Gemini 1.5 Pro 002\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-pro' display_name='Gemini 1.5 Pro' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-pro\n",
            "Display Name: Gemini 1.5 Pro\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-latest' display_name='Gemini 1.5 Flash Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-latest\n",
            "Display Name: Gemini 1.5 Flash Latest\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-001' display_name='Gemini 1.5 Flash 001' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-001\n",
            "Display Name: Gemini 1.5 Flash 001\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-001-tuning' display_name='Gemini 1.5 Flash 001 Tuning' description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=16384 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createTunedModel'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-001-tuning\n",
            "Display Name: Gemini 1.5 Flash 001 Tuning\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createTunedModel']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash' display_name='Gemini 1.5 Flash' description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash\n",
            "Display Name: Gemini 1.5 Flash\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-002' display_name='Gemini 1.5 Flash 002' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-002\n",
            "Display Name: Gemini 1.5 Flash 002\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b' display_name='Gemini 1.5 Flash-8B' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b\n",
            "Display Name: Gemini 1.5 Flash-8B\n",
            "Supported Actions: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b-001' display_name='Gemini 1.5 Flash-8B 001' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b-001\n",
            "Display Name: Gemini 1.5 Flash-8B 001\n",
            "Supported Actions: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b-latest' display_name='Gemini 1.5 Flash-8B Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b-latest\n",
            "Display Name: Gemini 1.5 Flash-8B Latest\n",
            "Supported Actions: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b-exp-0827' display_name='Gemini 1.5 Flash 8B Experimental 0827' description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b-exp-0827\n",
            "Display Name: Gemini 1.5 Flash 8B Experimental 0827\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b-exp-0924' display_name='Gemini 1.5 Flash 8B Experimental 0924' description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b-exp-0924\n",
            "Display Name: Gemini 1.5 Flash 8B Experimental 0924\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-exp-03-25' display_name='Gemini 2.5 Pro Experimental 03-25' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-exp-03-25\n",
            "Display Name: Gemini 2.5 Pro Experimental 03-25\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-preview-03-25' display_name='Gemini 2.5 Pro Preview 03-25' description='Gemini 2.5 Pro Preview 03-25' version='2.5-preview-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-preview-03-25\n",
            "Display Name: Gemini 2.5 Pro Preview 03-25\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-04-17' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-04-17\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-05-20' display_name='Gemini 2.5 Flash Preview 05-20' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-05-20' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-05-20\n",
            "Display Name: Gemini 2.5 Flash Preview 05-20\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-04-17-thinking' display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-04-17-thinking\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17 for cursor testing\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-preview-05-06' display_name='Gemini 2.5 Pro Preview 05-06' description='Preview release (May 6th, 2025) of Gemini 2.5 Pro' version='2.5-preview-05-06' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-preview-05-06\n",
            "Display Name: Gemini 2.5 Pro Preview 05-06\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-exp' display_name='Gemini 2.0 Flash Experimental' description='Gemini 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-exp\n",
            "Display Name: Gemini 2.0 Flash Experimental\n",
            "Supported Actions: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash' display_name='Gemini 2.0 Flash' description='Gemini 2.0 Flash' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash\n",
            "Display Name: Gemini 2.0 Flash\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-001' display_name='Gemini 2.0 Flash 001' description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-001\n",
            "Display Name: Gemini 2.0 Flash 001\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-exp-image-generation' display_name='Gemini 2.0 Flash (Image Generation) Experimental' description='Gemini 2.0 Flash (Image Generation) Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-exp-image-generation\n",
            "Display Name: Gemini 2.0 Flash (Image Generation) Experimental\n",
            "Supported Actions: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-lite-001' display_name='Gemini 2.0 Flash-Lite 001' description='Stable version of Gemini 2.0 Flash Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-lite-001\n",
            "Display Name: Gemini 2.0 Flash-Lite 001\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-lite' display_name='Gemini 2.0 Flash-Lite' description='Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-lite\n",
            "Display Name: Gemini 2.0 Flash-Lite\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-preview-image-generation' display_name='Gemini 2.0 Flash Preview Image Generation' description='Gemini 2.0 Flash Preview Image Generation' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-preview-image-generation\n",
            "Display Name: Gemini 2.0 Flash Preview Image Generation\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-lite-preview-02-05' display_name='Gemini 2.0 Flash-Lite Preview 02-05' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-lite-preview-02-05\n",
            "Display Name: Gemini 2.0 Flash-Lite Preview 02-05\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-lite-preview' display_name='Gemini 2.0 Flash-Lite Preview' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-lite-preview\n",
            "Display Name: Gemini 2.0 Flash-Lite Preview\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-pro-exp' display_name='Gemini 2.0 Pro Experimental' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-pro-exp\n",
            "Display Name: Gemini 2.0 Pro Experimental\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-pro-exp-02-05' display_name='Gemini 2.0 Pro Experimental 02-05' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-pro-exp-02-05\n",
            "Display Name: Gemini 2.0 Pro Experimental 02-05\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-exp-1206' display_name='Gemini Experimental 1206' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-exp-1206\n",
            "Display Name: Gemini Experimental 1206\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-thinking-exp-01-21' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-thinking-exp' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-thinking-exp\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-thinking-exp-1219' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-thinking-exp-1219\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-tts' display_name='Gemini 2.5 Flash Preview TTS' description='Gemini 2.5 Flash Preview TTS' version='gemini-2.5-flash-exp-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-tts\n",
            "Display Name: Gemini 2.5 Flash Preview TTS\n",
            "Supported Actions: ['countTokens', 'generateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-preview-tts' display_name='Gemini 2.5 Pro Preview TTS' description='Gemini 2.5 Pro Preview TTS' version='gemini-2.5-pro-preview-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=65536 output_token_limit=65536 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-preview-tts\n",
            "Display Name: Gemini 2.5 Pro Preview TTS\n",
            "Supported Actions: ['countTokens', 'generateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/learnlm-2.0-flash-experimental' display_name='LearnLM 2.0 Flash Experimental' description='LearnLM 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=32768 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/learnlm-2.0-flash-experimental\n",
            "Display Name: LearnLM 2.0 Flash Experimental\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3-1b-it' display_name='Gemma 3 1B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3-1b-it\n",
            "Display Name: Gemma 3 1B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3-4b-it' display_name='Gemma 3 4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3-4b-it\n",
            "Display Name: Gemma 3 4B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3-12b-it' display_name='Gemma 3 12B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3-12b-it\n",
            "Display Name: Gemma 3 12B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3-27b-it' display_name='Gemma 3 27B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3-27b-it\n",
            "Display Name: Gemma 3 27B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3n-e4b-it' display_name='Gemma 3n E4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3n-e4b-it\n",
            "Display Name: Gemma 3n E4B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/embedding-001' display_name='Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/embedding-001\n",
            "Display Name: Embedding 001\n",
            "Supported Actions: ['embedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/text-embedding-004' display_name='Text Embedding 004' description='Obtain a distributed representation of a text.' version='004' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/text-embedding-004\n",
            "Display Name: Text Embedding 004\n",
            "Supported Actions: ['embedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-embedding-exp-03-07' display_name='Gemini Embedding Experimental 03-07' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-embedding-exp-03-07\n",
            "Display Name: Gemini Embedding Experimental 03-07\n",
            "Supported Actions: ['embedContent', 'countTextTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-embedding-exp' display_name='Gemini Embedding Experimental' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-embedding-exp\n",
            "Display Name: Gemini Embedding Experimental\n",
            "Supported Actions: ['embedContent', 'countTextTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/aqa' display_name='Model that performs Attributed Question Answering.' description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=7168 output_token_limit=1024 supported_actions=['generateAnswer'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/aqa\n",
            "Display Name: Model that performs Attributed Question Answering.\n",
            "Supported Actions: ['generateAnswer']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/imagen-3.0-generate-002' display_name='Imagen 3.0 002 model' description='Vertex served Imagen 3.0 002 model' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/imagen-3.0-generate-002\n",
            "Display Name: Imagen 3.0 002 model\n",
            "Supported Actions: ['predict']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/veo-2.0-generate-001' display_name='Veo 2' description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/veo-2.0-generate-001\n",
            "Display Name: Veo 2\n",
            "Supported Actions: ['predictLongRunning']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-native-audio-dialog' display_name='Gemini 2.5 Flash Preview Native Audio Dialog' description='Gemini 2.5 Flash Preview Native Audio Dialog' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "Display Name: Gemini 2.5 Flash Preview Native Audio Dialog\n",
            "Supported Actions: ['countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3' display_name='Gemini 2.5 Flash Preview Native Audio Dialog RAI v3' description='Gemini 2.5 Flash Preview Native Audio Dialog RAI v3' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3\n",
            "Display Name: Gemini 2.5 Flash Preview Native Audio Dialog RAI v3\n",
            "Supported Actions: ['countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog' display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "Display Name: Gemini 2.5 Flash Exp Native Audio Thinking Dialog\n",
            "Supported Actions: ['countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-live-001' display_name='Gemini 2.0 Flash 001' description='Gemini 2.0 Flash 001' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['bidiGenerateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-live-001\n",
            "Display Name: Gemini 2.0 Flash 001\n",
            "Supported Actions: ['bidiGenerateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "\n",
            "All Tuned Model Details:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4: Get model details\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "try:\n",
        "    model_details = client.models.get(model=model_name) #\n",
        "    print(f\"Details for model '{model_name}':\")\n",
        "    print(f\"Model Name: {model_details.name}\")\n",
        "    print(f\"Input Token Limit: {model_details.input_token_limit}\")\n",
        "    print(f\"Output Token Limit: {model_details.output_token_limit}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving model details for '{model_name}': {e}\")"
      ],
      "metadata": {
        "id": "fVomhgC-t5j1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352f7854-46bf-423e-897c-8034cf26c847"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Details for model 'models/gemini-2.5-flash-preview-05-20':\n",
            "Model Name: models/gemini-2.5-flash-preview-05-20\n",
            "Input Token Limit: 1048576\n",
            "Output Token Limit: 65536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 5: few shot prompt\n",
        "prompt = \"\"\"\n",
        "Input: This movie was fantastic!\n",
        "Output: Positive\n",
        "\n",
        "Input: I was really disappointed with the service.\n",
        "Output: Negative\n",
        "\n",
        "Input: The weather is okay today.\n",
        "Output: Neutral\n",
        "\n",
        "Input: That concert was absolutely incredible!\n",
        "Output: ?\n",
        "\"\"\"\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "response = client.models.generate_content(\n",
        "  model=model_name,\n",
        "  contents=prompt\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "oppq_uJCvhux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a519f513-d4b7-4d73-dc98-71b5997a9d54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8a8Q1GS1eBIU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}