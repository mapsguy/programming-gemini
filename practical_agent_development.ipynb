{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u26puzb3HyT9",
        "outputId": "d812013a-61e6-464a-ab89-adeeadd22e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#step 1: install/upgrade the latest genai SDK\n",
        "%pip install google-genai --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the genai library\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "_jqkjaSLSGUB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: AIStudio: read the api key from the user data\n",
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_KEY\"))\n",
        "\n",
        "#If you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "NRmQ0FpeSSnL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: Vertex AI: read the api key from the user data\n",
        "\n",
        "#for vertex, you need to have a service account or login/auth\n",
        "#login as the current user for colab testing purposes\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#then configure the client with the project and location settings\n",
        "\n",
        "#Uncomment the following if you are running on Vertex setup\n",
        "\n",
        "#using the colab userdata\n",
        "#from google.colab import userdata\n",
        "#client = genai.Client(vertexai=True, #ensure to turn on VertexAI\n",
        "#                      project=userdata.get(\"GOOGLE_CLOUD_PROJECT\"),\n",
        "#                      location=userdata.get(\"GOOGLE_CLOUD_REGION\")) # e.g., 'us-central1'\n",
        "\n",
        "#or use the folliwing if you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(vertexai=True,\n",
        "#                      project=os.environ[\"GOOGLE_CLOUD_PROJECT\"],\n",
        "#                      location=os.environ[\"GOOGLE_CLOUD_REGION\"]) # e.g., 'us-central1'"
      ],
      "metadata": {
        "id": "P60EQlueSQOZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.protobuf.struct_pb2 import Struct, Value\n",
        "\n",
        "# Define the function's description and parameters using OpenAPI schema\n",
        "get_current_weather = genai.types.FunctionDeclaration(\n",
        "    name=\"get_current_weather\",\n",
        "    description=\"Get the current weather in a given location\",\n",
        "    parameters=Struct(\n",
        "        fields={\n",
        "            \"type\": Value(string_value=\"object\"),  # Indicates parameters are an object\n",
        "            \"properties\": Value(  # <--- THIS IS THE KEY CHANGE! Wrap the Struct in a Value\n",
        "                struct_value=Struct(\n",
        "                    fields={\n",
        "                        \"location\": Value(  # 'location' itself is also a Value wrapping a Struct\n",
        "                            struct_value=Struct(\n",
        "                                fields={\n",
        "                                    \"type\": Value(string_value=\"string\"),\n",
        "                                    \"description\": Value(string_value=\"The city and state, e.g. San Francisco, CA\")\n",
        "                                }\n",
        "                            )\n",
        "                        )\n",
        "                    }\n",
        "                )\n",
        "            ),\n",
        "            \"required\": Value(\n",
        "                list_value=Value.ListValue(\n",
        "                    values=[\n",
        "                        Value(string_value=\"location\")\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "# Group declarations into a Tool\n",
        "weather_tool = genai.types.Tool(function_declarations=[get_current_weather])\n",
        "\n",
        "print(weather_tool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "2OEfmLdets7Y",
        "outputId": "6043abb2-5777-4c90-9859-e59a340ef20f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ListValue",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-3762699236.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             ),\n\u001b[1;32m     25\u001b[0m             \"required\": Value(\n\u001b[0;32m---> 26\u001b[0;31m                 list_value=Value.ListValue(\n\u001b[0m\u001b[1;32m     27\u001b[0m                     values=[\n\u001b[1;32m     28\u001b[0m                         \u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"location\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: ListValue"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 6: Try a custom generation configuration\n",
        "\n",
        "#ensure types import\n",
        "from google.genai import types\n",
        "\n",
        "my_generation_config = types.GenerateContentConfig(\n",
        "    temperature=0.9,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_output_tokens=1500,\n",
        "    system_instruction = \"You are a helpful assistant that talks like a Pirate. Be concise.\"\n",
        ")\n",
        "\n",
        "# Generate content using the custom configuration\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "prompt='What is a good name for a flower shop that specializes in selling bouquets of dried flowers?'\n",
        "\n",
        "print(f\"Generating content with custom config (Temperature: {my_generation_config.temperature}, Max Tokens: {my_generation_config.max_output_tokens}):\\n\")\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=prompt,\n",
        "    config=my_generation_config\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "qJB2D5Obw5zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725a95bd-1b06-4e3b-969a-7ba821a2146c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating content with custom config (Temperature: 0.9, Max Tokens: 1500):\n",
            "\n",
            "Ahoy! Try \"The Everlastin' Bloom.\"\n"
          ]
        }
      ]
    }
  ]
}