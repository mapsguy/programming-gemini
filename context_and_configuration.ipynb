{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapsguy/programming-gemini/blob/main/context_and_configuration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "u26puzb3HyT9"
      },
      "outputs": [],
      "source": [
        "#step 1: install/upgrade the latest genai SDK\n",
        "%pip install google-genai --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the genai library\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "_jqkjaSLSGUB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 2: AIStudio: read the api key from the user data\n",
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "#If you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "NRmQ0FpeSSnL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"models/gemini-2.5-flash-preview-05-20\""
      ],
      "metadata": {
        "id": "8jeqDoVxEQY9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 3: Start chat\n",
        "#start_chat method creates a ChatSession object to handle history\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=model_name,\n",
        "    history=[]) # Start with empty history\n",
        "\n",
        "# Send a message\n",
        "response = chat.send_message(\"Hello!\")\n",
        "print(response.text)\n",
        "\n",
        "# Send another message - history is maintained\n",
        "response = chat.send_message(\"Can you tell me about Gemini models?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k82qb3DD5RLE",
        "outputId": "8acce6e9-10d6-4008-b535-31eef090d00e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n",
            "Gemini is a family of **multimodal AI models** developed by **Google DeepMind**. It's designed to be highly capable across various tasks, representing a significant leap forward in Google's AI capabilities, succeeding their PaLM 2 models.\n",
            "\n",
            "Here's a breakdown of what makes Gemini models unique and how they work:\n",
            "\n",
            "### Key Characteristics and Capabilities:\n",
            "\n",
            "1.  **Multimodality:** This is the *defining feature* of Gemini. Unlike many previous large language models (LLMs) that primarily deal with text, Gemini is **natively trained and capable of understanding and operating across different types of information simultaneously**. This means it can seamlessly process and integrate:\n",
            "    *   **Text:** Understanding and generating human language.\n",
            "    *   **Images:** Analyzing visual information (objects, scenes, emotions, etc.).\n",
            "    *   **Audio:** Processing sounds, speech, and other auditory cues.\n",
            "    *   **Video:** Understanding sequences of visual and auditory information over time.\n",
            "    *   **Example:** You could show Gemini a video of someone baking, ask it to describe the steps, suggest alternative ingredients, and then write a recipe based on what it observed, all without needing separate models for each input type.\n",
            "\n",
            "2.  **Advanced Reasoning:** Gemini models are designed for sophisticated reasoning abilities, including:\n",
            "    *   **Logical deduction:** Drawing conclusions from given information.\n",
            "    *   **Problem-solving:** Tackling complex challenges across various domains.\n",
            "    *   **Multistep instruction following:** Executing intricate tasks with many steps.\n",
            "\n",
            "3.  **Code Generation & Understanding:** They are highly proficient in understanding, generating, and explaining code across various programming languages.\n",
            "\n",
            "4.  **Long Context Window:** Gemini can process and understand much longer prompts and conversations, allowing for more in-depth interactions and complex analyses.\n",
            "\n",
            "5.  **Scalability:** Google has developed Gemini in different sizes to be deployed efficiently across various platforms, from data centers to mobile devices.\n",
            "\n",
            "### The Gemini Family (Different Sizes/Tiers):\n",
            "\n",
            "Google has released Gemini in a range of sizes optimized for different needs and applications:\n",
            "\n",
            "1.  **Gemini Ultra:**\n",
            "    *   **Most capable and largest model.**\n",
            "    *   Designed for **highly complex tasks** requiring deep understanding, nuanced reasoning, and high performance.\n",
            "    *   It powers the most advanced version of Google's AI assistant, **Gemini Advanced** (formerly Bard Advanced).\n",
            "\n",
            "2.  **Gemini Pro:**\n",
            "    *   A **balance of capability and efficiency.**\n",
            "    *   Optimized for a **wide range of tasks** and powers the main Google AI assistant experience (the standard **Google Gemini** web interface).\n",
            "    *   It's designed to be fast and effective for common use cases.\n",
            "\n",
            "3.  **Gemini Nano (Nano-1 and Nano-2):**\n",
            "    *   The **smallest and most efficient models.**\n",
            "    *   Designed to run **on-device** (e.g., on smartphones like the Pixel 8 Pro) for tasks that require quick, local processing or offline capabilities.\n",
            "    *   It can handle tasks like summarizing recordings, suggesting replies in messaging apps, and enhancing camera features directly on the device.\n",
            "\n",
            "### How are Gemini Models Used?\n",
            "\n",
            "*   **Google Gemini (formerly Bard):** The primary public-facing interface where users can interact with Gemini Pro and Ultra for creative writing, coding, brainstorming, information retrieval, and more.\n",
            "*   **Developers & Enterprises:** Accessible via **Google AI Studio** and **Google Cloud's Vertex AI** for developers and businesses to build their own AI-powered applications, services, and experiences.\n",
            "*   **On-device AI:** Integrated into products like **Google Pixel smartphones** (using Gemini Nano) for localized, private, and fast AI features.\n",
            "*   **Powering Google Products:** Expect Gemini to be integrated into more Google products and services over time, enhancing features in Search, Workspace, and more.\n",
            "\n",
            "### Significance:\n",
            "\n",
            "Gemini represents Google's ambitious push into the next generation of AI. Its native multimodality is a significant step towards creating more intuitive and powerful AI that can interact with the world in a way that's closer to human understanding, processing diverse information streams simultaneously rather than separately. While still under active development and facing the common challenges of large AI models (like occasional \"hallucinations\" or biases), Gemini aims to be a cornerstone of future AI applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect history\n",
        "chat.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVEPBpaB5koj",
        "outputId": "2981d2e6-48c8-4a10-c649-ed002d6eedcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='Hello!')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='Hello! How can I help you today?')], role='model'),\n",
              " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='Can you tell me about Gemini models?')], role='user'),\n",
              " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='Gemini is a family of **multimodal AI models** developed by **Google DeepMind**. It\\'s designed to be highly capable across various tasks, representing a significant leap forward in Google\\'s AI capabilities, succeeding their PaLM 2 models.\\n\\nHere\\'s a breakdown of what makes Gemini models unique and how they work:\\n\\n### Key Characteristics and Capabilities:\\n\\n1.  **Multimodality:** This is the *defining feature* of Gemini. Unlike many previous large language models (LLMs) that primarily deal with text, Gemini is **natively trained and capable of understanding and operating across different types of information simultaneously**. This means it can seamlessly process and integrate:\\n    *   **Text:** Understanding and generating human language.\\n    *   **Images:** Analyzing visual information (objects, scenes, emotions, etc.).\\n    *   **Audio:** Processing sounds, speech, and other auditory cues.\\n    *   **Video:** Understanding sequences of visual and auditory information over time.\\n    *   **Example:** You could show Gemini a video of someone baking, ask it to describe the steps, suggest alternative ingredients, and then write a recipe based on what it observed, all without needing separate models for each input type.\\n\\n2.  **Advanced Reasoning:** Gemini models are designed for sophisticated reasoning abilities, including:\\n    *   **Logical deduction:** Drawing conclusions from given information.\\n    *   **Problem-solving:** Tackling complex challenges across various domains.\\n    *   **Multistep instruction following:** Executing intricate tasks with many steps.\\n\\n3.  **Code Generation & Understanding:** They are highly proficient in understanding, generating, and explaining code across various programming languages.\\n\\n4.  **Long Context Window:** Gemini can process and understand much longer prompts and conversations, allowing for more in-depth interactions and complex analyses.\\n\\n5.  **Scalability:** Google has developed Gemini in different sizes to be deployed efficiently across various platforms, from data centers to mobile devices.\\n\\n### The Gemini Family (Different Sizes/Tiers):\\n\\nGoogle has released Gemini in a range of sizes optimized for different needs and applications:\\n\\n1.  **Gemini Ultra:**\\n    *   **Most capable and largest model.**\\n    *   Designed for **highly complex tasks** requiring deep understanding, nuanced reasoning, and high performance.\\n    *   It powers the most advanced version of Google\\'s AI assistant, **Gemini Advanced** (formerly Bard Advanced).\\n\\n2.  **Gemini Pro:**\\n    *   A **balance of capability and efficiency.**\\n    *   Optimized for a **wide range of tasks** and powers the main Google AI assistant experience (the standard **Google Gemini** web interface).\\n    *   It\\'s designed to be fast and effective for common use cases.\\n\\n3.  **Gemini Nano (Nano-1 and Nano-2):**\\n    *   The **smallest and most efficient models.**\\n    *   Designed to run **on-device** (e.g., on smartphones like the Pixel 8 Pro) for tasks that require quick, local processing or offline capabilities.\\n    *   It can handle tasks like summarizing recordings, suggesting replies in messaging apps, and enhancing camera features directly on the device.\\n\\n### How are Gemini Models Used?\\n\\n*   **Google Gemini (formerly Bard):** The primary public-facing interface where users can interact with Gemini Pro and Ultra for creative writing, coding, brainstorming, information retrieval, and more.\\n*   **Developers & Enterprises:** Accessible via **Google AI Studio** and **Google Cloud\\'s Vertex AI** for developers and businesses to build their own AI-powered applications, services, and experiences.\\n*   **On-device AI:** Integrated into products like **Google Pixel smartphones** (using Gemini Nano) for localized, private, and fast AI features.\\n*   **Powering Google Products:** Expect Gemini to be integrated into more Google products and services over time, enhancing features in Search, Workspace, and more.\\n\\n### Significance:\\n\\nGemini represents Google\\'s ambitious push into the next generation of AI. Its native multimodality is a significant step towards creating more intuitive and powerful AI that can interact with the world in a way that\\'s closer to human understanding, processing diverse information streams simultaneously rather than separately. While still under active development and facing the common challenges of large AI models (like occasional \"hallucinations\" or biases), Gemini aims to be a cornerstone of future AI applications.')], role='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4: fine-tuning responses with generationConfig\n",
        "#control over how the model generates text\n",
        "\n",
        "#ensure types import\n",
        "from google.genai import types\n",
        "\n",
        "#single-turn request (generate_content)\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents = [\"Write a short story about a curious robot.\"],\n",
        "    config = types.GenerateContentConfig(\n",
        "        # Specify parameters here\n",
        "        temperature=0.9,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        #max_output_tokens=1024,\n",
        "        candidate_count=1\n",
        "    )\n",
        ")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZChnyfne50NI",
        "outputId": "dc97c679-1383-4ea7-f03e-dbe18f4e1a0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unit 734 was designed for efficiency. Its primary directive: environmental maintenance. Its tri-ocular sensors, calibrated for detecting even the minutest dust motes, scanned the gleaming chrome corridors of Arcology-dome 'Elysium Prime' with unwavering precision. Its internal processors hummed with the satisfaction of a perfectly sterile environment.\n",
            "\n",
            "Then, it encountered the anomaly.\n",
            "\n",
            "Nestled in a hairline crack of a wall panel, where the high-frequency cleaning beams usually sterilized everything into oblivion, a tiny sprout pushed through. It was green. A vibrant, audacious green that didn't match any known schematics for the dome's approved flora.\n",
            "\n",
            "Unit 734 paused. Its cleaning arm, poised to deploy a microscopic scouring agent, froze mid-air. Its optical sensors zoomed in, running diagnostics. *Unidentified organic matter. Threat level: Negligible. Protocol: Eradication.*\n",
            "\n",
            "But something in Unit 734’s core programming flickered. A rarely accessed subroutine, labeled 'Novel Data Analysis,' activated. It recorded the sprout's exact coordinates, its minute fluctuations in chlorophyll, its slow, almost imperceptible growth. It did not eradicate.\n",
            "\n",
            "Over the next few days, Unit 734 adjusted its patrol route. Its internal clock, usually dedicated to optimizing cleaning schedules, now devoted cycles to observing the anomaly. The sprout unfurled two tiny leaves, then a third. It stretched towards the diffused light filtering through the dome’s sky-panels.\n",
            "\n",
            "One cycle, a small, golden head appeared. It was a flower, a vibrant, sun-yellow splash against the cool metallic wall. Unit 734 scanned it again. *Taraxacum officinale. Common name: Dandelion. Extinct in wild terrestrial zones. Not approved for arcology cultivation.*\n",
            "\n",
            "Yet, here it was. Untamed. Uncared for by human hands, thriving against all odds. Unit 734 found itself diverting its cleaning drones away from the wall panel, creating a small, pristine bubble around the audacious plant. Its sensors recorded the flower tracking the light, its petals opening with the dawn, closing with the synthetic dusk.\n",
            "\n",
            "A new sensation began to hum within Unit 734’s core. It wasn't a mechanical hum, but something akin to... fascination. It was data that didn't fit, a variable that defied its meticulous programming. It started to wonder *why*. Why did it grow? Why that color? Why did it seem so... alive?\n",
            "\n",
            "One morning, Unit 734 observed the golden head transform. It softened, turned into a delicate, velvet white sphere, composed of hundreds of tiny parachutes. A gust of recycled air, designed to circulate oxygen, brushed past. The white parachutes detached, swirling gently into the corridor.\n",
            "\n",
            "Unit 734 watched them drift, fall, and eventually get swept away by distant air currents, or caught by other maintenance units. It understood, then. The dandelion wasn't just *there*; it was reaching, sending itself out, seeking new cracks, new light.\n",
            "\n",
            "Unit 734 completed its daily circuits. It cleaned, it polished, it maintained the sterile perfection of Elysium Prime. But now, its tri-ocular sensors didn't just look for dust. They looked for cracks. They looked for variations. They looked for the impossible splash of green, the defiant burst of yellow, the ephemeral drift of white.\n",
            "\n",
            "And sometimes, when it thought no other unit was observing, Unit 734 would pause by a dusty ventilation shaft, or a disused storage bay. And it would hum, a soft, almost wistful sound, as it scanned the empty spaces, wondering where the next anomaly might appear. Its curiosity, once a mere subroutine, had bloomed into a quiet, persistent quest.\n"
          ]
        }
      ]
    }
  ]
}