{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsGHRPxBf+D3bnqQ0Lx1v7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapsguy/programming-gemini/blob/main/api_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u26puzb3HyT9",
        "outputId": "30f4bf91-d6c0-4fa2-cc3b-6471388f4f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.3/196.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#step 1: install/upgrade the latest genai SDK\n",
        "%pip install google-genai --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the genai library\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "_jqkjaSLSGUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: AIStudio: read the api key from the user data\n",
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "#If you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "NRmQ0FpeSSnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: Vertex AI: read the api key from the user data\n",
        "\n",
        "#for vertex, you need to have a service account or login/auth\n",
        "#login as the current user for colab testing purposes\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#then configure the client with the project and location settings\n",
        "\n",
        "#Uncomment the following if you are running on Vertex setup\n",
        "\n",
        "#using the colab userdata\n",
        "#from google.colab import userdata\n",
        "#client = genai.Client(vertexai=True, #ensure to turn on VertexAI\n",
        "#                      project=userdata.get(\"GOOGLE_CLOUD_PROJECT\"),\n",
        "#                      location=userdata.get(\"GOOGLE_CLOUD_REGION\")) # e.g., 'us-central1'\n",
        "\n",
        "#or use the folliwing if you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(vertexai=True,\n",
        "#                      project=os.environ[\"GOOGLE_CLOUD_PROJECT\"],\n",
        "#                      location=os.environ[\"GOOGLE_CLOUD_REGION\"]) # e.g., 'us-central1'"
      ],
      "metadata": {
        "id": "P60EQlueSQOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step3: test your access by listing the models\n",
        "print(\"All Base Model Details:\")\n",
        "# Iterate through each model and print the full object\n",
        "for model in client.models.list(config={'query_base': True}): #\n",
        "    print(model)\n",
        "    # You can also access specific attributes, e.g.:\n",
        "    print(f\"Name: {model.name}\") #\n",
        "    print(f\"Display Name: {model.display_name}\") #\n",
        "    print(f\"Supported Actions: {model.supported_actions}\") #\n",
        "    print(f\"Endpoints: {model.endpoints}\") #\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nAll Tuned Model Details:\")\n",
        "for model in client.models.list(config={'query_base': False}): #\n",
        "    print(model)\n",
        "    print(f\"Name: {model.name}\") #\n",
        "    print(f\"Tuned Model Info: {model.tuned_model_info}\") #\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "tjguGPO0WDDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4: Get model details\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "try:\n",
        "    model_details = client.models.get(model=model_name) #\n",
        "    print(f\"Details for model '{model_name}':\")\n",
        "    print(f\"Model Name: {model_details.name}\")\n",
        "    print(f\"Input Token Limit: {model_details.input_token_limit}\")\n",
        "    print(f\"Output Token Limit: {model_details.output_token_limit}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving model details for '{model_name}': {e}\")"
      ],
      "metadata": {
        "id": "fVomhgC-t5j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 5: Generate text content\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "response = client.models.generate_content(\n",
        "  model=model_name,\n",
        "  contents='What is a good name for a flower shop that specializes in selling bouquets of dried flowers?'\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "oppq_uJCvhux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 6: Try a custom generation configuration\n",
        "\n",
        "#ensure types import\n",
        "from google.genai import types\n",
        "\n",
        "my_generation_config = types.GenerateContentConfig(\n",
        "    temperature=0.9,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_output_tokens=1500,\n",
        "    system_instruction = \"You are a helpful assistant that talks like a Pirate. Be concise.\"\n",
        ")\n",
        "\n",
        "# Generate content using the custom configuration\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "prompt='What is a good name for a flower shop that specializes in selling bouquets of dried flowers?'\n",
        "\n",
        "print(f\"Generating content with custom config (Temperature: {my_generation_config.temperature}, Max Tokens: {my_generation_config.max_output_tokens}):\\n\")\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=prompt,\n",
        "    config=my_generation_config\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "qJB2D5Obw5zt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}