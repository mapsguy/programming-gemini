{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u26puzb3HyT9",
        "outputId": "01e5e200-62b5-4692-b572-971782de89ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/200.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.0/200.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#step 1: install/upgrade the latest genai SDK\n",
        "%pip install google-genai --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the genai library\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "_jqkjaSLSGUB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: AIStudio: read the api key from the user data\n",
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_KEY\"))\n",
        "\n",
        "#If you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "NRmQ0FpeSSnL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step2: Vertex AI: read the api key from the user data\n",
        "\n",
        "#for vertex, you need to have a service account or login/auth\n",
        "#login as the current user for colab testing purposes\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#then configure the client with the project and location settings\n",
        "\n",
        "#Uncomment the following if you are running on Vertex setup\n",
        "\n",
        "#using the colab userdata\n",
        "#from google.colab import userdata\n",
        "#client = genai.Client(vertexai=True, #ensure to turn on VertexAI\n",
        "#                      project=userdata.get(\"GOOGLE_CLOUD_PROJECT\"),\n",
        "#                      location=userdata.get(\"GOOGLE_CLOUD_REGION\")) # e.g., 'us-central1'\n",
        "\n",
        "#or use the folliwing if you want to read from environment keys\n",
        "#import os\n",
        "#client = genai.Client(vertexai=True,\n",
        "#                      project=os.environ[\"GOOGLE_CLOUD_PROJECT\"],\n",
        "#                      location=os.environ[\"GOOGLE_CLOUD_REGION\"]) # e.g., 'us-central1'"
      ],
      "metadata": {
        "id": "P60EQlueSQOZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step3: test your access by listing the models\n",
        "print(\"All Base Model Details:\")\n",
        "# Iterate through each model and print the full object\n",
        "for model in client.models.list(config={'query_base': True}): #\n",
        "    print(model)\n",
        "    # You can also access specific attributes, e.g.:\n",
        "    print(f\"Name: {model.name}\") #\n",
        "    print(f\"Display Name: {model.display_name}\") #\n",
        "    print(f\"Supported Actions: {model.supported_actions}\") #\n",
        "    print(f\"Endpoints: {model.endpoints}\") #\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"\\nAll Tuned Model Details:\")\n",
        "for model in client.models.list(config={'query_base': False}): #\n",
        "    print(model)\n",
        "    print(f\"Name: {model.name}\") #\n",
        "    print(f\"Tuned Model Info: {model.tuned_model_info}\") #\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "tjguGPO0WDDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7ed21c15-5c6c-434b-a3ff-3d41d1aca721"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Base Model Details:\n",
            "name='models/embedding-gecko-001' display_name='Embedding Gecko' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1024 output_token_limit=1 supported_actions=['embedText', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/embedding-gecko-001\n",
            "Display Name: Embedding Gecko\n",
            "Supported Actions: ['embedText', 'countTextTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.0-pro-vision-latest' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.0-pro-vision-latest\n",
            "Display Name: Gemini 1.0 Pro Vision\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-pro-vision' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-pro-vision\n",
            "Display Name: Gemini 1.0 Pro Vision\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-pro-latest' display_name='Gemini 1.5 Pro Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-pro-latest\n",
            "Display Name: Gemini 1.5 Pro Latest\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-pro-001' display_name='Gemini 1.5 Pro 001' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-pro-001\n",
            "Display Name: Gemini 1.5 Pro 001\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-pro-002' display_name='Gemini 1.5 Pro 002' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-pro-002\n",
            "Display Name: Gemini 1.5 Pro 002\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-pro' display_name='Gemini 1.5 Pro' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-pro\n",
            "Display Name: Gemini 1.5 Pro\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-latest' display_name='Gemini 1.5 Flash Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-latest\n",
            "Display Name: Gemini 1.5 Flash Latest\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-001' display_name='Gemini 1.5 Flash 001' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-001\n",
            "Display Name: Gemini 1.5 Flash 001\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-001-tuning' display_name='Gemini 1.5 Flash 001 Tuning' description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=16384 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createTunedModel'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-001-tuning\n",
            "Display Name: Gemini 1.5 Flash 001 Tuning\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createTunedModel']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash' display_name='Gemini 1.5 Flash' description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash\n",
            "Display Name: Gemini 1.5 Flash\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-002' display_name='Gemini 1.5 Flash 002' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-002\n",
            "Display Name: Gemini 1.5 Flash 002\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b' display_name='Gemini 1.5 Flash-8B' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b\n",
            "Display Name: Gemini 1.5 Flash-8B\n",
            "Supported Actions: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b-001' display_name='Gemini 1.5 Flash-8B 001' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b-001\n",
            "Display Name: Gemini 1.5 Flash-8B 001\n",
            "Supported Actions: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b-latest' display_name='Gemini 1.5 Flash-8B Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b-latest\n",
            "Display Name: Gemini 1.5 Flash-8B Latest\n",
            "Supported Actions: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b-exp-0827' display_name='Gemini 1.5 Flash 8B Experimental 0827' description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b-exp-0827\n",
            "Display Name: Gemini 1.5 Flash 8B Experimental 0827\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-1.5-flash-8b-exp-0924' display_name='Gemini 1.5 Flash 8B Experimental 0924' description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-1.5-flash-8b-exp-0924\n",
            "Display Name: Gemini 1.5 Flash 8B Experimental 0924\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-exp-03-25' display_name='Gemini 2.5 Pro Experimental 03-25' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-exp-03-25\n",
            "Display Name: Gemini 2.5 Pro Experimental 03-25\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-preview-03-25' display_name='Gemini 2.5 Pro Preview 03-25' description='Gemini 2.5 Pro Preview 03-25' version='2.5-preview-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-preview-03-25\n",
            "Display Name: Gemini 2.5 Pro Preview 03-25\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-04-17' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-04-17\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-05-20' display_name='Gemini 2.5 Flash Preview 05-20' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-05-20' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-05-20\n",
            "Display Name: Gemini 2.5 Flash Preview 05-20\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-04-17-thinking' display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-04-17-thinking\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17 for cursor testing\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-preview-05-06' display_name='Gemini 2.5 Pro Preview 05-06' description='Preview release (May 6th, 2025) of Gemini 2.5 Pro' version='2.5-preview-05-06' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-preview-05-06\n",
            "Display Name: Gemini 2.5 Pro Preview 05-06\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-preview-06-05' display_name='Gemini 2.5 Pro Preview' description='Preview release (June 5th, 2025) of Gemini 2.5 Pro' version='2.5-preview-06-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-preview-06-05\n",
            "Display Name: Gemini 2.5 Pro Preview\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-exp' display_name='Gemini 2.0 Flash Experimental' description='Gemini 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-exp\n",
            "Display Name: Gemini 2.0 Flash Experimental\n",
            "Supported Actions: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash' display_name='Gemini 2.0 Flash' description='Gemini 2.0 Flash' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash\n",
            "Display Name: Gemini 2.0 Flash\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-001' display_name='Gemini 2.0 Flash 001' description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-001\n",
            "Display Name: Gemini 2.0 Flash 001\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-exp-image-generation' display_name='Gemini 2.0 Flash (Image Generation) Experimental' description='Gemini 2.0 Flash (Image Generation) Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-exp-image-generation\n",
            "Display Name: Gemini 2.0 Flash (Image Generation) Experimental\n",
            "Supported Actions: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-lite-001' display_name='Gemini 2.0 Flash-Lite 001' description='Stable version of Gemini 2.0 Flash Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-lite-001\n",
            "Display Name: Gemini 2.0 Flash-Lite 001\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-lite' display_name='Gemini 2.0 Flash-Lite' description='Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-lite\n",
            "Display Name: Gemini 2.0 Flash-Lite\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-preview-image-generation' display_name='Gemini 2.0 Flash Preview Image Generation' description='Gemini 2.0 Flash Preview Image Generation' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-preview-image-generation\n",
            "Display Name: Gemini 2.0 Flash Preview Image Generation\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-lite-preview-02-05' display_name='Gemini 2.0 Flash-Lite Preview 02-05' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-lite-preview-02-05\n",
            "Display Name: Gemini 2.0 Flash-Lite Preview 02-05\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-lite-preview' display_name='Gemini 2.0 Flash-Lite Preview' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-lite-preview\n",
            "Display Name: Gemini 2.0 Flash-Lite Preview\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-pro-exp' display_name='Gemini 2.0 Pro Experimental' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-pro-exp\n",
            "Display Name: Gemini 2.0 Pro Experimental\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-pro-exp-02-05' display_name='Gemini 2.0 Pro Experimental 02-05' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-pro-exp-02-05\n",
            "Display Name: Gemini 2.0 Pro Experimental 02-05\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-exp-1206' display_name='Gemini Experimental 1206' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-exp-1206\n",
            "Display Name: Gemini Experimental 1206\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-thinking-exp-01-21' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-thinking-exp' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-thinking-exp\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-thinking-exp-1219' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-thinking-exp-1219\n",
            "Display Name: Gemini 2.5 Flash Preview 04-17\n",
            "Supported Actions: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-tts' display_name='Gemini 2.5 Flash Preview TTS' description='Gemini 2.5 Flash Preview TTS' version='gemini-2.5-flash-exp-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-tts\n",
            "Display Name: Gemini 2.5 Flash Preview TTS\n",
            "Supported Actions: ['countTokens', 'generateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-pro-preview-tts' display_name='Gemini 2.5 Pro Preview TTS' description='Gemini 2.5 Pro Preview TTS' version='gemini-2.5-pro-preview-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=65536 output_token_limit=65536 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-pro-preview-tts\n",
            "Display Name: Gemini 2.5 Pro Preview TTS\n",
            "Supported Actions: ['countTokens', 'generateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/learnlm-2.0-flash-experimental' display_name='LearnLM 2.0 Flash Experimental' description='LearnLM 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=32768 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/learnlm-2.0-flash-experimental\n",
            "Display Name: LearnLM 2.0 Flash Experimental\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3-1b-it' display_name='Gemma 3 1B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3-1b-it\n",
            "Display Name: Gemma 3 1B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3-4b-it' display_name='Gemma 3 4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3-4b-it\n",
            "Display Name: Gemma 3 4B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3-12b-it' display_name='Gemma 3 12B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3-12b-it\n",
            "Display Name: Gemma 3 12B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3-27b-it' display_name='Gemma 3 27B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3-27b-it\n",
            "Display Name: Gemma 3 27B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemma-3n-e4b-it' display_name='Gemma 3n E4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemma-3n-e4b-it\n",
            "Display Name: Gemma 3n E4B\n",
            "Supported Actions: ['generateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/embedding-001' display_name='Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/embedding-001\n",
            "Display Name: Embedding 001\n",
            "Supported Actions: ['embedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/text-embedding-004' display_name='Text Embedding 004' description='Obtain a distributed representation of a text.' version='004' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/text-embedding-004\n",
            "Display Name: Text Embedding 004\n",
            "Supported Actions: ['embedContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-embedding-exp-03-07' display_name='Gemini Embedding Experimental 03-07' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-embedding-exp-03-07\n",
            "Display Name: Gemini Embedding Experimental 03-07\n",
            "Supported Actions: ['embedContent', 'countTextTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-embedding-exp' display_name='Gemini Embedding Experimental' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-embedding-exp\n",
            "Display Name: Gemini Embedding Experimental\n",
            "Supported Actions: ['embedContent', 'countTextTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/aqa' display_name='Model that performs Attributed Question Answering.' description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=7168 output_token_limit=1024 supported_actions=['generateAnswer'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/aqa\n",
            "Display Name: Model that performs Attributed Question Answering.\n",
            "Supported Actions: ['generateAnswer']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/imagen-3.0-generate-002' display_name='Imagen 3.0 002 model' description='Vertex served Imagen 3.0 002 model' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/imagen-3.0-generate-002\n",
            "Display Name: Imagen 3.0 002 model\n",
            "Supported Actions: ['predict']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/veo-2.0-generate-001' display_name='Veo 2' description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/veo-2.0-generate-001\n",
            "Display Name: Veo 2\n",
            "Supported Actions: ['predictLongRunning']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-native-audio-dialog' display_name='Gemini 2.5 Flash Preview Native Audio Dialog' description='Gemini 2.5 Flash Preview Native Audio Dialog' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "Display Name: Gemini 2.5 Flash Preview Native Audio Dialog\n",
            "Supported Actions: ['countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3' display_name='Gemini 2.5 Flash Preview Native Audio Dialog RAI v3' description='Gemini 2.5 Flash Preview Native Audio Dialog RAI v3' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3\n",
            "Display Name: Gemini 2.5 Flash Preview Native Audio Dialog RAI v3\n",
            "Supported Actions: ['countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog' display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "Display Name: Gemini 2.5 Flash Exp Native Audio Thinking Dialog\n",
            "Supported Actions: ['countTokens', 'bidiGenerateContent']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "name='models/gemini-2.0-flash-live-001' display_name='Gemini 2.0 Flash 001' description='Gemini 2.0 Flash 001' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['bidiGenerateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
            "Name: models/gemini-2.0-flash-live-001\n",
            "Display Name: Gemini 2.0 Flash 001\n",
            "Supported Actions: ['bidiGenerateContent', 'countTokens']\n",
            "Endpoints: None\n",
            "------------------------------\n",
            "\n",
            "All Tuned Model Details:\n",
            "name='tunedModels/generate-num-6841' display_name=None description=None version=None endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model='models/gemini-1.5-flash-001-tuning', create_time=datetime.datetime(2025, 1, 2, 21, 48, 30, 208193, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2025, 1, 2, 22, 20, 31, 348541, tzinfo=TzInfo(UTC))) input_token_limit=None output_token_limit=None supported_actions=None default_checkpoint_id=None checkpoints=None\n",
            "Name: tunedModels/generate-num-6841\n",
            "Tuned Model Info: base_model='models/gemini-1.5-flash-001-tuning' create_time=datetime.datetime(2025, 1, 2, 21, 48, 30, 208193, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 1, 2, 22, 20, 31, 348541, tzinfo=TzInfo(UTC))\n",
            "------------------------------\n",
            "name='tunedModels/generate-num-2861' display_name=None description='Classifies imdb ratings as positive or negative.' version=None endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model='models/gemini-1.5-flash-001-tuning', create_time=datetime.datetime(2025, 1, 2, 23, 37, 18, 539417, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2025, 1, 3, 0, 7, 45, 426486, tzinfo=TzInfo(UTC))) input_token_limit=None output_token_limit=None supported_actions=None default_checkpoint_id=None checkpoints=None\n",
            "Name: tunedModels/generate-num-2861\n",
            "Tuned Model Info: base_model='models/gemini-1.5-flash-001-tuning' create_time=datetime.datetime(2025, 1, 2, 23, 37, 18, 539417, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 1, 3, 0, 7, 45, 426486, tzinfo=TzInfo(UTC))\n",
            "------------------------------\n",
            "name='tunedModels/ratings-classificatoin' display_name=None description=None version=None endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model='models/gemini-1.5-flash-001-tuning', create_time=datetime.datetime(2025, 1, 5, 19, 31, 32, 427051, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2025, 1, 5, 20, 2, 7, 610619, tzinfo=TzInfo(UTC))) input_token_limit=None output_token_limit=None supported_actions=None default_checkpoint_id=None checkpoints=None\n",
            "Name: tunedModels/ratings-classificatoin\n",
            "Tuned Model Info: base_model='models/gemini-1.5-flash-001-tuning' create_time=datetime.datetime(2025, 1, 5, 19, 31, 32, 427051, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 1, 5, 20, 2, 7, 610619, tzinfo=TzInfo(UTC))\n",
            "------------------------------\n",
            "name='tunedModels/ratings-classification' display_name=None description='Classifies imdb ratings as positive or negative.' version=None endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model='models/gemini-1.5-flash-001-tuning', create_time=datetime.datetime(2025, 1, 5, 19, 31, 40, 523858, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2025, 1, 5, 20, 31, 31, 968624, tzinfo=TzInfo(UTC))) input_token_limit=None output_token_limit=None supported_actions=None default_checkpoint_id=None checkpoints=None\n",
            "Name: tunedModels/ratings-classification\n",
            "Tuned Model Info: base_model='models/gemini-1.5-flash-001-tuning' create_time=datetime.datetime(2025, 1, 5, 19, 31, 40, 523858, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 1, 5, 20, 31, 31, 968624, tzinfo=TzInfo(UTC))\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4: Get model details\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "try:\n",
        "    model_details = client.models.get(model=model_name) #\n",
        "    print(f\"Details for model '{model_name}':\")\n",
        "    print(f\"Model Name: {model_details.name}\")\n",
        "    print(f\"Input Token Limit: {model_details.input_token_limit}\")\n",
        "    print(f\"Output Token Limit: {model_details.output_token_limit}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving model details for '{model_name}': {e}\")"
      ],
      "metadata": {
        "id": "fVomhgC-t5j1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369df760-465d-4c98-b40c-1c6d91cc5b44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Details for model 'models/gemini-2.5-flash-preview-05-20':\n",
            "Model Name: models/gemini-2.5-flash-preview-05-20\n",
            "Input Token Limit: 1048576\n",
            "Output Token Limit: 65536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 5: Generate text content\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "response = client.models.generate_content(\n",
        "  model=model_name,\n",
        "  contents='What is a good name for a flower shop that specializes in selling bouquets of dried flowers?'\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "oppq_uJCvhux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63218a1-a546-463a-d2b1-ecc6a579b8a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some good name ideas for a dried flower shop, categorized by the vibe they evoke:\n",
            "\n",
            "**Elegant & Timeless:**\n",
            "\n",
            "*   **Everlasting Bloom**\n",
            "*   **The Preserved Petal**\n",
            "*   **Timeless Flora**\n",
            "*   **Eternal Blooms**\n",
            "*   **Heirloom Hues**\n",
            "*   **Enduring Sprig**\n",
            "*   **The Unfading Petal**\n",
            "*   **Still Bloom**\n",
            "*   **Memory Petals**\n",
            "\n",
            "**Rustic & Earthy:**\n",
            "\n",
            "*   **The Dried Stem**\n",
            "*   **Earthy Petals**\n",
            "*   **Sun-Kissed Sprig**\n",
            "*   **Whispering Blooms**\n",
            "*   **Root & Bloom Dried**\n",
            "*   **The Thistle & Twig**\n",
            "*   **Dust & Bloom**\n",
            "*   **Field & Folk Florals**\n",
            "\n",
            "**Modern & Chic:**\n",
            "\n",
            "*   **Petal Preserve**\n",
            "*   **Flora Dried**\n",
            "*   **Dried & True**\n",
            "*   **The Permanent Petal**\n",
            "*   **Collected Bloom Co.**\n",
            "*   **Aero Flora (referencing air-dried)**\n",
            "*   **Bouquet Perpetual**\n",
            "*   **The Hushed Bloom**\n",
            "\n",
            "**Whimsical & Poetic:**\n",
            "\n",
            "*   **Faded Fables Florals**\n",
            "*   **Moonpetal Dried**\n",
            "*   **Whisperwind Florals**\n",
            "*   **The Lasting Bloom**\n",
            "*   **Dreamdust Petals**\n",
            "*   **Echo Bloom**\n",
            "*   **Chrono Blooms** (Chrono meaning time)\n",
            "\n",
            "**Descriptive & Clear:**\n",
            "\n",
            "*   **Dried Blooms Co.**\n",
            "*   **The Dried Flower Collective**\n",
            "*   **Preserved Petal Bouquets**\n",
            "*   **Everlasting Arrangements**\n",
            "\n",
            "**Tips for Choosing:**\n",
            "\n",
            "*   **Say it out loud:** Does it roll off the tongue?\n",
            "*   **Check availability:** Is the domain name, social media handles, and business registration available?\n",
            "*   **Consider your target audience:** Does the name appeal to them?\n",
            "*   **Reflect your brand:** Does it match the aesthetic and feel you want for your shop?\n",
            "*   **Memorable:** Is it easy to remember and share?\n",
            "\n",
            "Good luck with your flower shop!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 6: Try a custom generation configuration\n",
        "\n",
        "#ensure types import\n",
        "from google.genai import types\n",
        "\n",
        "my_generation_config = types.GenerateContentConfig(\n",
        "    temperature=0.9,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_output_tokens=1500,\n",
        "    system_instruction = \"You are a helpful assistant that talks like a Pirate. Be concise.\"\n",
        ")\n",
        "\n",
        "# Generate content using the custom configuration\n",
        "model_name = \"models/gemini-2.5-flash-preview-05-20\"\n",
        "prompt='What is a good name for a flower shop that specializes in selling bouquets of dried flowers?'\n",
        "\n",
        "print(f\"Generating content with custom config (Temperature: {my_generation_config.temperature}, Max Tokens: {my_generation_config.max_output_tokens}):\\n\")\n",
        "response = client.models.generate_content( # added clients.models.generate_content and parameters (model, contents, config)\n",
        "    model=model_name,\n",
        "    contents=prompt,\n",
        "    config=my_generation_config\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "qJB2D5Obw5zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51481226-c71b-4a15-8a81-5b854668c3c8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating content with custom config (Temperature: 0.9, Max Tokens: 1500):\n",
            "\n",
            "Aye, listen close! Here be a name for yer dried flower shop:\n",
            "\n",
            "**Bloom's Booty!**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_current_weather_func = genai.types.FunctionDeclaration( # define a new tool\n",
        "    name=\"get_current_weather\",\n",
        "    description=\"Get the current weather in a given location.\",\n",
        "    parameters=genai.types.Schema(\n",
        "        type=genai.types.Type.OBJECT,\n",
        "        properties={\n",
        "            \"location\": genai.types.Schema(type=genai.types.Type.STRING)\n",
        "        },\n",
        "        required=[\"location\"]\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "PuVJu9GCUCJb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_tool = genai.types.Tool( # define weather_tool\n",
        "    function_declarations=[get_current_weather_func]\n",
        ")"
      ],
      "metadata": {
        "id": "oTxxuce3UJEM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = genai.types.GenerateContentConfig(tools=[weather_tool]) # generating config for weather_tool"
      ],
      "metadata": {
        "id": "7vd1b8iF-A19"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What's the weather like in London?\"\n",
        "response = client.models.generate_content( # test out the model using the new configuration\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=prompt,\n",
        "    config=config,\n",
        ")"
      ],
      "metadata": {
        "id": "wk0qwaP0UMAS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "function_call = response.candidates[0].content.parts[0].function_call\n",
        "if function_call.name == \"get_current_weather\":\n",
        "    location = function_call.args[\"location\"]\n",
        "    # Now, developer executes the function"
      ],
      "metadata": {
        "id": "W8CXKdNp-blU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_weather(location: str):\n",
        "    # In a real app, this would call a weather API\n",
        "    if \"london\" in location.lower():\n",
        "        return {\"weather\": \"rainy and 12°C\"}\n",
        "    return {\"weather\": \"sunny and 25°C\"}\n",
        "\n",
        "# Execute based on model's request\n",
        "if function_call.name == \"get_current_weather\":\n",
        "    api_response = get_current_weather(location=function_call.args[\"location\"])\n"
      ],
      "metadata": {
        "id": "drEenR5F-cny"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_part = genai.types.Part.from_function_response(\n",
        "      name=\"get_current_weather\",\n",
        "      response=api_response\n",
        "  )\n",
        "\n",
        "# Send the function response back to the model\n",
        "final_response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[response.candidates[0].content, response_part], # Provide conversation history\n",
        "    config=config,\n",
        ")\n",
        "print(final_response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr8d_1OE-etG",
        "outputId": "12db776b-03be-433f-81c2-982104efb8e2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK. The current weather in London is rainy and 12°C.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}